{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.master('local').config('spark.driver.memory', '8g').appName('Ready_for_analysis').getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\n",
    "    '/Users/gabriele.sabato/PycharmProjects/raw_data/price_elasticity_model_data/part-*',\n",
    "    header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('model_data_table')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+--------------+-----------+-----+\n",
      "|         item_code|update_date|delivery_weeks| item_price|sales|\n",
      "+------------------+-----------+--------------+-----------+-----+\n",
      "|000000001000000008| 2019-01-26|             1|      13.99|    0|\n",
      "|000000001000000008| 2019-04-12|             0|      13.99|    0|\n",
      "|000000001000000008| 2019-06-22|             1|      13.99|    0|\n",
      "|000000001000000008| 2019-08-13|             1|      13.99|    0|\n",
      "|000000001000000008| 2019-12-27|             0|      13.99|    0|\n",
      "|000000001000000013| 2018-12-18|             1|      39.99|    0|\n",
      "|000000001000000013| 2020-01-30|             1|      39.99|    0|\n",
      "|000000001000000013| 2020-10-26|             0|31.98999999|    0|\n",
      "|000000001000000013| 2020-10-27|             0|31.98999999|    0|\n",
      "|000000001000000014| 2019-04-19|             1|74.98999999|    0|\n",
      "|000000001000000014| 2019-06-16|             1|74.98999999|    0|\n",
      "|000000001000000014| 2019-11-10|             0|74.98999999|    0|\n",
      "|000000001000000014| 2020-01-14|             0|74.98999999|    0|\n",
      "|000000001000000016| 2019-07-30|             1|       79.9|    0|\n",
      "|000000001000000017| 2019-03-14|             1|      129.9|    0|\n",
      "|000000001000000020| 2019-01-07|             1|84.98999999|    0|\n",
      "|000000001000000020| 2019-02-18|             1|84.98999999|    0|\n",
      "|000000001000000020| 2019-09-13|             1|84.98999999|    0|\n",
      "|000000001000000020| 2020-03-30|             1|74.98999999|    0|\n",
      "|000000001000000020| 2020-04-27|             0|74.98999999|    0|\n",
      "+------------------+-----------+--------------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"SELECT * from model_data_table where update_date >= '2020-01-01' ORDER BY update_date \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView('model_data_table_YTD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one_item_df = spark.sql(\" SELECT item_code, update_date, item_price, delivery_weeks, sales from model_data_table_YTD  \"\n",
    "                       \"where item_code = '000000001000016021' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+------------+--------------+-----+\n",
      "|         item_code|update_date|  item_price|delivery_weeks|sales|\n",
      "+------------------+-----------+------------+--------------+-----+\n",
      "|000000001000016021| 2020-01-01|119.98999999|             5|   23|\n",
      "|000000001000016021| 2020-01-02|119.98999999|             1|    7|\n",
      "|000000001000016021| 2020-01-03|119.98999999|             4|   15|\n",
      "|000000001000016021| 2020-01-04|119.98999999|             4|   16|\n",
      "|000000001000016021| 2020-01-05|119.98999999|             4|   17|\n",
      "|000000001000016021| 2020-01-06|119.98999999|             4|   18|\n",
      "|000000001000016021| 2020-01-07|119.98999999|             4|    3|\n",
      "|000000001000016021| 2020-01-08|119.98999999|             3|    8|\n",
      "|000000001000016021| 2020-01-09|119.98999999|             3|    9|\n",
      "|000000001000016021| 2020-01-10|119.98999999|             1|   18|\n",
      "|000000001000016021| 2020-01-11|119.98999999|             1|    9|\n",
      "|000000001000016021| 2020-01-12|119.98999999|             3|   28|\n",
      "|000000001000016021| 2020-01-13|119.98999999|             3|   12|\n",
      "|000000001000016021| 2020-01-14|119.98999999|             3|    9|\n",
      "|000000001000016021| 2020-01-15|119.98999999|             2|    3|\n",
      "|000000001000016021| 2020-01-16|119.98999999|             2|   11|\n",
      "|000000001000016021| 2020-01-17|119.98999999|             2|   27|\n",
      "|000000001000016021| 2020-01-18|119.98999999|             2|   18|\n",
      "|000000001000016021| 2020-01-19|119.98999999|             2|   22|\n",
      "|000000001000016021| 2020-01-20|119.98999999|             2|   18|\n",
      "+------------------+-----------+------------+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_item_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE A TABLE VIEW FOR ITEM_CODE = 000000001000016021\n",
    "one_item_df.createOrReplaceTempView('top_seller')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_NAME = 'top_seller'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "group_by_cons_rows = \"\"\"WITH tmp_tbl AS (\n",
    "      SELECT *,\n",
    "             CASE\n",
    "                 WHEN lag(delivery_weeks, 1) OVER (PARTITION BY delivery_weeks, item_price ORDER BY update_date ASC) =\n",
    "                      delivery_weeks\n",
    "                     THEN delivery_weeks\n",
    "                 ELSE ROW_NUMBER() OVER (ORDER BY update_date)\n",
    "                 END AS grouping_dw_col --filled with row number or delivery week if the previous one is part of the same group,\n",
    "        FROM {table_name}\n",
    "  ),\n",
    "       tmp_tbl2 AS (\n",
    "           SELECT update_date,\n",
    "                  item_code,\n",
    "                  sales,\n",
    "                  item_price,\n",
    "                  delivery_weeks,\n",
    "                  CASE\n",
    "                      WHEN lag(delivery_weeks, 1) OVER (PARTITION BY delivery_weeks, item_price ORDER BY update_date) =\n",
    "                           delivery_weeks\n",
    "                          THEN lag(grouping_dw_col, 1) OVER (ORDER BY update_date)\n",
    "                      ELSE ROW_NUMBER() OVER (ORDER BY update_date)\n",
    "                      END AS grouping_col_dw\n",
    "             FROM tmp_tbl\n",
    "       )\n",
    "SELECT MIN(update_date)                   AS min_date,\n",
    "       MAX(update_date)                   AS max_date,\n",
    "       item_code,\n",
    "       item_price,\n",
    "       delivery_weeks,\n",
    "       avg(sales),\n",
    "       (datediff(MAX(update_date),MIN(update_date)) + 1) AS bin_width \n",
    "  FROM tmp_tbl2\n",
    " GROUP BY grouping_col_dw, delivery_weeks, item_price, item_code\n",
    " ORDER BY MIN(update_date)\"\"\".format(table_name= TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH tmp_tbl AS (\n",
      "      SELECT *,\n",
      "             CASE\n",
      "                 WHEN lag(delivery_weeks, 1) OVER (PARTITION BY delivery_weeks, item_price ORDER BY update_date ASC) =\n",
      "                      delivery_weeks\n",
      "                     THEN delivery_weeks\n",
      "                 ELSE ROW_NUMBER() OVER (ORDER BY update_date)\n",
      "                 END AS grouping_dw_col --filled with row number or delivery week if the previous one is part of the same group,\n",
      "        FROM top_seller\n",
      "  ),\n",
      "       tmp_tbl2 AS (\n",
      "           SELECT update_date,\n",
      "                  item_code,\n",
      "                  sales,\n",
      "                  item_price,\n",
      "                  delivery_weeks,\n",
      "                  CASE\n",
      "                      WHEN lag(delivery_weeks, 1) OVER (PARTITION BY delivery_weeks, item_price ORDER BY update_date) =\n",
      "                           delivery_weeks\n",
      "                          THEN lag(grouping_dw_col, 1) OVER (ORDER BY update_date)\n",
      "                      ELSE ROW_NUMBER() OVER (ORDER BY update_date)\n",
      "                      END AS grouping_col_dw\n",
      "             FROM tmp_tbl\n",
      "       )\n",
      "SELECT MIN(update_date)                   AS min_date,\n",
      "       MAX(update_date)                   AS max_date,\n",
      "       item_code,\n",
      "       item_price,\n",
      "       delivery_weeks,\n",
      "       avg(sales),\n",
      "       (datediff(MAX(update_date),MIN(update_date)) + 1) AS bin_width \n",
      "  FROM tmp_tbl2\n",
      " GROUP BY grouping_col_dw, delivery_weeks, item_price, item_code\n",
      " ORDER BY MIN(update_date)\n"
     ]
    }
   ],
   "source": [
    "print(group_by_cons_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_try_grouping = spark.sql(group_by_cons_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+------------+--------------+------------------+---------+\n",
      "|  min_date|  max_date|         item_code|  item_price|delivery_weeks|        avg(sales)|bin_width|\n",
      "+----------+----------+------------------+------------+--------------+------------------+---------+\n",
      "|2020-01-01|2020-01-01|000000001000016021|119.98999999|             5|              23.0|        1|\n",
      "|2020-01-02|2020-08-14|000000001000016021|119.98999999|             1|              8.25|      226|\n",
      "|2020-01-03|2020-01-04|000000001000016021|119.98999999|             4|              15.5|        2|\n",
      "|2020-01-05|2020-01-07|000000001000016021|119.98999999|             4|12.666666666666666|        3|\n",
      "|2020-01-08|2020-01-09|000000001000016021|119.98999999|             3|               8.5|        2|\n",
      "|2020-01-10|2020-01-10|000000001000016021|119.98999999|             1|              18.0|        1|\n",
      "|2020-01-11|2020-10-23|000000001000016021|119.98999999|             1|18.793357933579337|      287|\n",
      "|2020-01-12|2020-01-12|000000001000016021|119.98999999|             3|              28.0|        1|\n",
      "|2020-01-13|2020-01-14|000000001000016021|119.98999999|             3|              10.5|        2|\n",
      "|2020-01-15|2020-01-16|000000001000016021|119.98999999|             2|               7.0|        2|\n",
      "|2020-01-17|2020-08-13|000000001000016021|119.98999999|             2|              18.5|      210|\n",
      "|2020-08-10|2020-08-12|000000001000016021|119.98999999|             2|              10.0|        3|\n",
      "|2020-10-24|2020-10-25|000000001000016021|109.98999999|             1|              20.5|        2|\n",
      "|2020-10-26|2020-11-18|000000001000016021|109.98999999|             1|32.916666666666664|       24|\n",
      "+----------+----------+------------------+------------+--------------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_try_grouping.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one_item_df.write.csv('/tmp/one_item_pel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one_item_df.toPandas().to_csv('/Users/gabriele.sabato/Downloads/one_item_pel.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}